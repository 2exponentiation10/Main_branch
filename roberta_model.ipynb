{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Data/processed_train2.csv\")\n",
    "test= pd.read_csv(\"Data/processed_test2.csv\")\n",
    "submission = pd.read_csv(\"Data/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지금 당장 뉴스 기사 내가 불러준 대로 보도 해  사실 확인이 되지 않은 기사는 낼...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이 버러지 같은 게 너 내가 누군 줄 알아  손님 욕하시면 안 됩니다   어디서 말...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>공책 돌려받길 원하면 빨리 뛰어봐  이 굼벵아  빨리 내놔  빨릐 내놓아야  빨리 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사장님 저기 말할게 있는데요 뭔데 임마 아니 우리 게임 회사는 전체이용가 게임이잖아...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>죽고 싶어서 환장했어  왜 이렇게 말을 안 들어   죄송해요  한 번만 봐주세요  ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>야 이 시계 예쁜데 생일선물로 받은거야 이거 나 주고 가라 안돼 이게 어디 까불어 ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>새로 생긴 카페 가봤어  아니  아직 안 가봤어  거기 커피 진짜 맛있어  그래  ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>야 너 이리 와봐 이게 뭐야  네  뭐가 문제가 생겼나요 이새끼봐라 니가 뭘 했다고...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>아니 지금 장난해  보고서가 이따위가 뭐야 지금  죄송합니다   죄송이고 나발이고 ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>형 그러지 마  왜 갑자기 나한테 그래 너야 말로 미쳤어  너 때문에 우리 다 망하...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation  class\n",
       "0  지금 당장 뉴스 기사 내가 불러준 대로 보도 해  사실 확인이 되지 않은 기사는 낼...    0.0\n",
       "1  이 버러지 같은 게 너 내가 누군 줄 알아  손님 욕하시면 안 됩니다   어디서 말...    1.0\n",
       "2  공책 돌려받길 원하면 빨리 뛰어봐  이 굼벵아  빨리 내놔  빨릐 내놓아야  빨리 ...    1.0\n",
       "3  사장님 저기 말할게 있는데요 뭔데 임마 아니 우리 게임 회사는 전체이용가 게임이잖아...    3.0\n",
       "4  죽고 싶어서 환장했어  왜 이렇게 말을 안 들어   죄송해요  한 번만 봐주세요  ...    0.0\n",
       "5  야 이 시계 예쁜데 생일선물로 받은거야 이거 나 주고 가라 안돼 이게 어디 까불어 ...    2.0\n",
       "6  새로 생긴 카페 가봤어  아니  아직 안 가봤어  거기 커피 진짜 맛있어  그래  ...    4.0\n",
       "7  야 너 이리 와봐 이게 뭐야  네  뭐가 문제가 생겼나요 이새끼봐라 니가 뭘 했다고...    3.0\n",
       "8  아니 지금 장난해  보고서가 이따위가 뭐야 지금  죄송합니다   죄송이고 나발이고 ...    3.0\n",
       "9  형 그러지 마  왜 갑자기 나한테 그래 너야 말로 미쳤어  너 때문에 우리 다 망하...    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4552, 2)\n",
      "(500, 1)\n",
      "(500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape) #train 약 45백개\n",
    "print(test.shape) # test 약 5백개\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHRCAYAAABU7dwoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqKklEQVR4nO3dfXSMd/7/8Vcid0QmaWgmspSUtNjGTWk1brdkRRs9LN3FZt2X/WrsVn3bfumiRW1U1VrWym5XE1p0q2dpaTcV0WURoVFFKKrqpkxSJRlSkpD5/eHnOh2irXbymRHPxzlzTnJdn7nmHbN79rnXXDPj53K5XAIAAIAR/t4eAAAA4FZCfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAGoMT7//HP5+fnJz89PmZmZ3h4HAKpEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAHwaZs3b9Zjjz2mu+++WzabTUFBQWrYsKF69+6tBQsWqLi4+IaOt2fPHr3wwgtKSkpSw4YNFRwcrLp16youLk5Dhw7V1q1bv/MYJ06c0IQJE3TvvfcqPDxcgYGBstvtio+P16BBg5SZmSmn01nlfVeuXKm+fftajx0WFqY777xTXbp00eTJk7Vt27Yb+nsA3IRcAOCDvv76a9egQYNckr719txzz1n3OXz4sLU9IyPjmmN+8MEH33k8Sa4JEyZcd66NGze6bDbbdx5j9erVbve7ePGi65e//OV33q9du3ae+icE4KMCqrntAOCGVVZWqk+fPsrOzpYkxcXF6fHHH1f79u1Vp04dnTx5Ulu2bNGbb755Q8e9ePGiQkNDlZycrO7du6t58+ay2WwqKipSQUGB5s2bpyNHjmjmzJm66667NHz4cLf7l5WVaeDAgXI6nQoLC9OYMWP04IMPKioqSuXl5Tp8+LC2bNmilStXXvPYCxcu1IoVKyRJnTt31mOPPaamTZsqNDRUX331lXbt2qWsrCyVlJT8wH81ADcLP5fL5fL2EADwTfPmzdMTTzwhSfrFL36h5cuXKzg4+Jp1lZWVOnnypH7yk59Iuvwhq7GxsZKkjIwMDRs2zG39qVOnFBAQoIiIiCoft7y8XL1791Z2drYaN26sQ4cOqVatWtb+9evXq0ePHpKk1atXq3fv3lUe5+LFi/r6669ls9msbV27dtV///tfdejQQZs2bVJAQNX/3/f06dOKjIysch+AmoFrvgD4lMrKSr300kuSpIYNG2rJkiVVhpck+fv7W+H1fdSvX/+64SVJQUFB1mMfOXJEO3fudNvvcDisn7t27Xrd4wQEBLiF1zfv27Fjx+uGlyTCC7gFEF8AfMrOnTt1/PhxSdKoUaNUt27danussrIyHT16VHv37tWePXu0Z88effPFgI8//thtfYMGDayfMzIybuixrtx39erVOnXq1I+YGsDNjvgC4FM++ugj6+cuXbp4/PilpaVKS0tT69atFRoaqsaNG+unP/2p4uPjFR8fr7Zt21prr46kzp07684775QkjRs3Tvfff7/S0tK0efNmlZeXf+vjDh06VJL06aefqlmzZhoxYoSWL19uhSaAWwcX3APwKd8Mnm+eafKEzz//XN27d9fhw4e/1/rz58+7/R4YGKjVq1fr0Ucf1b59+7R9+3Zt375dklS7dm117dpVQ4YM0YABA9yuFZOkESNG6NChQ5o1a5ZKSkqUkZFhnT1r2rSp+vTpo9TUVCvuANRcnPkCcMsYPHiwDh8+LD8/P40YMUJr167VsWPHdOHCBVVWVsrlcunSpUvW+qrej9SyZUvt3r1bK1eu1IgRI9SsWTNJl0Pt/fffV0pKijp06KCioqJr7jtjxgx9+umnmjFjhrp37646depIkg4dOqQ5c+aoefPmSk9Pr6a/HoCvIL4A+JT69etbP588edJjx/3kk0+0adMmSdKzzz6rRYsW6ec//7n1Yad+fn6SLr/b8LvUqlVLffv21aJFi3Tw4EGdOHFCr776qtq1aydJys/P129/+9sq79u4cWM9++yzysnJUXFxsTZv3qwnnnhCISEhqqio0OOPP+720iuAmof4AuBT7r33XuvnjRs3euy4BQUF1s8DBgy47roPP/zwho/doEEDDR8+XLm5udb8a9asueZly6sFBgaqY8eOmjt3rpYtWybp8tm2t95664ZnAHDzIL4A+JTWrVurUaNGkqR//OMfOnfunEeOe/HiRevn0tLS6677MS/7BQYGqlu3btbj3chXH135/DDp2gv9AdQsxBcAn+Lv76+nn35aknT8+HENGTLkuu8krKys1IkTJ77XcePi4qyfMzMzq1yzcOFCvf3229c9xn//+199+umn191fXl6uDRs2SJLq1q2r22+/3dr3+uuvuwXg1dauXWv9fOWDYgHUTLzbEYDPSU1N1erVq5Wdna2VK1cqPj7e7euFHA6Htm7dquXLl+vXv/61nn/++e88Ztu2bXXPPfdoz549+tvf/qYzZ85o8ODBatCggY4fP67XX39db731ljp16qTNmzdXeYycnBxNnz5dXbp0UXJyslq1aqXbb79d58+f14EDB5Senq4dO3ZIkkaOHOn2YaqDBw/WU089pX79+qljx45q2rSpQkJCVFhYqOzsbC1cuFDS5WhLSUn58f+IAHwW8QXA5/j7+2vVqlUaOnSo3nrrLR04cEDjxo37Ucf08/PTa6+9pu7du+vMmTN68803r/luyPj4eK1YsUIxMTHXPU5lZaU2bNhgneGqSp8+fZSWlnbN9sLCQi1cuNAKrauFh4frjTfesF52BVAzEV8AfFKdOnW0YsUKffDBB8rIyNCmTZvkcDh06dIl2e12tWnTRr1799agQYO+9zHbtGmjnTt3Ki0tTf/+97914sQJhYWFqVmzZvrVr36l1NRUhYSEXPf+Tz31lFq1aqV169bpo48+0okTJ6yPlIiOjtb999+vIUOGKDk5+Zr77tmzR++++642bdqkQ4cOqbCwUMXFxQoLC1Pz5s2VlJSkMWPGyG633/g/FoCbCl+sDQAAYBAX3AMAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhEfAEAABhUYz/n68rXjoSFhcnPz8/b4wAAgBrM5XLp7NmziomJkb//t5/bqrHxdeLECT4lGgAAGHXs2DE1bNjwW9fU2PgKCwuTdPkfwWazeXkaAABQkzmdTjVq1Mjqj29TY+PrykuNNpuN+AIAAEZ8n0uduOAeAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAIOILAADAoBuOr40bN+qRRx5RTEyM/Pz8tGrVKrf9LpdLU6ZMUYMGDVS7dm0lJibq4MGDbmtOnz6tlJQU2Ww2RUREaOTIkTp37pzbml27dqlLly4KCQlRo0aNNGvWrBv/6wAAAHxMwI3eobS0VK1bt9aIESPUr1+/a/bPmjVL8+bN0+LFixUbG6vJkycrKSlJe/fuVUhIiCQpJSVFJ0+eVHZ2tioqKjR8+HCNHj1ay5YtkyQ5nU717NlTiYmJSk9P1+7duzVixAhFRERo9OjRP/JPxq2uyYR3vT1Ctfl8ZrK3RwAAfAc/l8vl+sF39vPTypUr1bdvX0mXz3rFxMTof//3f/XUU09JkkpKSmS325WZmamBAwdq3759atmypbZv36727dtLkrKysvTwww/r+PHjiomJ0cKFC/WHP/xBDodDQUFBkqQJEyZo1apV+uSTT77XbE6nU+Hh4SopKZHNZvuhfyJqIOILAOBpN9IdHr3m6/Dhw3I4HEpMTLS2hYeHq0OHDsrNzZUk5ebmKiIiwgovSUpMTJS/v7/y8vKsNV27drXCS5KSkpK0f/9+nTlzxpMjAwAAGHXDLzt+G4fDIUmy2+1u2+12u7XP4XAoKirKfYiAAEVGRrqtiY2NveYYV/bddttt1zx2WVmZysrKrN+dTueP/GsAAAA8r8a82zEtLU3h4eHWrVGjRt4eCQAA4Boeja/o6GhJUmFhodv2wsJCa190dLSKiorc9l+8eFGnT592W1PVMb75GFebOHGiSkpKrNuxY8d+/B8EAADgYR6Nr9jYWEVHRysnJ8fa5nQ6lZeXp4SEBElSQkKCiouLlZ+fb61Zv369Kisr1aFDB2vNxo0bVVFRYa3Jzs7W3XffXeVLjpIUHBwsm83mdgMAAPA1Nxxf586d086dO7Vz505Jly+y37lzp44ePSo/Pz+NGzdOL7zwgt555x3t3r1bQ4YMUUxMjPWOyBYtWqhXr14aNWqUtm3bps2bN2vs2LEaOHCgYmJiJEm//vWvFRQUpJEjR6qgoED//Oc/9ec//1njx4/32B8OAADgDTd8wf2HH36oBx980Pr9ShANHTpUmZmZeuaZZ1RaWqrRo0eruLhYnTt3VlZWlvUZX5K0dOlSjR07Vj169JC/v7/69++vefPmWfvDw8O1du1apaamql27dqpfv76mTJnCZ3wBAICb3o/6nC9fxud84Xr4nC8AgKd57XO+AAAA8O2ILwAAAIOILwAAAIM8+gn3AFBdauq1elynB9x6iC8AQLWoqcEsEc34cXjZEQAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwCDiCwAAwKAAbw9ws2sy4V1vj1AtPp+Z7O0RAACokTjzBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYJDH4+vSpUuaPHmyYmNjVbt2bTVt2lTTp0+Xy+Wy1rhcLk2ZMkUNGjRQ7dq1lZiYqIMHD7od5/Tp00pJSZHNZlNERIRGjhypc+fOeXpcAAAAozweXy+++KIWLlyov/zlL9q3b59efPFFzZo1S/Pnz7fWzJo1S/PmzVN6erry8vIUGhqqpKQkXbhwwVqTkpKigoICZWdna82aNdq4caNGjx7t6XEBAACMCvD0Abds2aI+ffooOTlZktSkSRMtX75c27Ztk3T5rNfcuXM1adIk9enTR5K0ZMkS2e12rVq1SgMHDtS+ffuUlZWl7du3q3379pKk+fPn6+GHH9bs2bMVExPj6bEBAACM8PiZr44dOyonJ0cHDhyQJH388cfatGmTHnroIUnS4cOH5XA4lJiYaN0nPDxcHTp0UG5uriQpNzdXERERVnhJUmJiovz9/ZWXl1fl45aVlcnpdLrdAAAAfI3Hz3xNmDBBTqdTzZs3V61atXTp0iXNmDFDKSkpkiSHwyFJstvtbvez2+3WPofDoaioKPdBAwIUGRlprblaWlqapk6d6uk/BwAAwKM8fubrzTff1NKlS7Vs2TLt2LFDixcv1uzZs7V48WJPP5SbiRMnqqSkxLodO3asWh8PAADgh/D4ma+nn35aEyZM0MCBAyVJ8fHxOnLkiNLS0jR06FBFR0dLkgoLC9WgQQPrfoWFhWrTpo0kKTo6WkVFRW7HvXjxok6fPm3d/2rBwcEKDg729J8DAADgUR4/8/X111/L39/9sLVq1VJlZaUkKTY2VtHR0crJybH2O51O5eXlKSEhQZKUkJCg4uJi5efnW2vWr1+vyspKdejQwdMjAwAAGOPxM1+PPPKIZsyYoTvuuEM//elP9dFHH2nOnDkaMWKEJMnPz0/jxo3TCy+8oLi4OMXGxmry5MmKiYlR3759JUktWrRQr169NGrUKKWnp6uiokJjx47VwIEDeacjAAC4qXk8vubPn6/Jkyfr8ccfV1FRkWJiYvTb3/5WU6ZMsdY888wzKi0t1ejRo1VcXKzOnTsrKytLISEh1pqlS5dq7Nix6tGjh/z9/dW/f3/NmzfP0+MCAAAY5fH4CgsL09y5czV37tzrrvHz89O0adM0bdq0666JjIzUsmXLPD0eAACAV/HdjgAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYRXwAAAAYFeHsAAADgO5pMeNfbI1Sbz2cme3sESZz5AgAAMIr4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMIj4AgAAMKha4uuLL77Qb37zG9WrV0+1a9dWfHy8PvzwQ2u/y+XSlClT1KBBA9WuXVuJiYk6ePCg2zFOnz6tlJQU2Ww2RUREaOTIkTp37lx1jAsAAGCMx+PrzJkz6tSpkwIDA/Xvf/9be/fu1csvv6zbbrvNWjNr1izNmzdP6enpysvLU2hoqJKSknThwgVrTUpKigoKCpSdna01a9Zo48aNGj16tKfHBQAAMCrA0wd88cUX1ahRI2VkZFjbYmNjrZ9dLpfmzp2rSZMmqU+fPpKkJUuWyG63a9WqVRo4cKD27dunrKwsbd++Xe3bt5ckzZ8/Xw8//LBmz56tmJgYT48NAABghMfPfL3zzjtq3769fvnLXyoqKkpt27bVK6+8Yu0/fPiwHA6HEhMTrW3h4eHq0KGDcnNzJUm5ubmKiIiwwkuSEhMT5e/vr7y8PE+PDAAAYIzH4+uzzz7TwoULFRcXp/fff19jxozR73//ey1evFiS5HA4JEl2u93tfna73drncDgUFRXltj8gIECRkZHWmquVlZXJ6XS63QAAAHyNx192rKysVPv27fXHP/5RktS2bVvt2bNH6enpGjp0qKcfzpKWlqapU6dW2/EBAAA8weNnvho0aKCWLVu6bWvRooWOHj0qSYqOjpYkFRYWuq0pLCy09kVHR6uoqMht/8WLF3X69GlrzdUmTpyokpIS63bs2DGP/D0AAACe5PH46tSpk/bv3++27cCBA2rcuLGkyxffR0dHKycnx9rvdDqVl5enhIQESVJCQoKKi4uVn59vrVm/fr0qKyvVoUOHKh83ODhYNpvN7QYAAOBrPP6y45NPPqmOHTvqj3/8o371q19p27Zt+vvf/66///3vkiQ/Pz+NGzdOL7zwguLi4hQbG6vJkycrJiZGffv2lXT5TFmvXr00atQopaenq6KiQmPHjtXAgQN5pyMAALipeTy+7rvvPq1cuVITJ07UtGnTFBsbq7lz5yolJcVa88wzz6i0tFSjR49WcXGxOnfurKysLIWEhFhrli5dqrFjx6pHjx7y9/dX//79NW/ePE+PCwAAYJTH40uSevfurd69e193v5+fn6ZNm6Zp06Zdd01kZKSWLVtWHeMBAAB4Dd/tCAAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYBDxBQAAYFC1x9fMmTPl5+encePGWdsuXLig1NRU1atXT3Xr1lX//v1VWFjodr+jR48qOTlZderUUVRUlJ5++mldvHixuscFAACoVtUaX9u3b9ff/vY3tWrVym37k08+qdWrV2vFihXasGGDTpw4oX79+ln7L126pOTkZJWXl2vLli1avHixMjMzNWXKlOocFwAAoNpVW3ydO3dOKSkpeuWVV3TbbbdZ20tKSrRo0SLNmTNH3bt3V7t27ZSRkaEtW7Zo69atkqS1a9dq7969ev3119WmTRs99NBDmj59uhYsWKDy8vLqGhkAAKDaVVt8paamKjk5WYmJiW7b8/PzVVFR4ba9efPmuuOOO5SbmytJys3NVXx8vOx2u7UmKSlJTqdTBQUFVT5eWVmZnE6n2w0AAMDXBFTHQd944w3t2LFD27dvv2afw+FQUFCQIiIi3Lbb7XY5HA5rzTfD68r+K/uqkpaWpqlTp3pgegAAgOrj8TNfx44d0xNPPKGlS5cqJCTE04e/rokTJ6qkpMS6HTt2zNhjAwAAfF8ej6/8/HwVFRXp3nvvVUBAgAICArRhwwbNmzdPAQEBstvtKi8vV3Fxsdv9CgsLFR0dLUmKjo6+5t2PV36/suZqwcHBstlsbjcAAABf4/H46tGjh3bv3q2dO3dat/bt2yslJcX6OTAwUDk5OdZ99u/fr6NHjyohIUGSlJCQoN27d6uoqMhak52dLZvNppYtW3p6ZAAAAGM8fs1XWFiY7rnnHrdtoaGhqlevnrV95MiRGj9+vCIjI2Wz2fS73/1OCQkJeuCBByRJPXv2VMuWLTV48GDNmjVLDodDkyZNUmpqqoKDgz09MgAAgDHVcsH9d/nTn/4kf39/9e/fX2VlZUpKStJf//pXa3+tWrW0Zs0ajRkzRgkJCQoNDdXQoUM1bdo0b4wLAADgMUbi6z//+Y/b7yEhIVqwYIEWLFhw3fs0btxY7733XjVPBgAAYBbf7QgAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGAQ8QUAAGCQx+MrLS1N9913n8LCwhQVFaW+fftq//79bmsuXLig1NRU1atXT3Xr1lX//v1VWFjotubo0aNKTk5WnTp1FBUVpaeffloXL1709LgAAABGeTy+NmzYoNTUVG3dulXZ2dmqqKhQz549VVpaaq158skntXr1aq1YsUIbNmzQiRMn1K9fP2v/pUuXlJycrPLycm3ZskWLFy9WZmampkyZ4ulxAQAAjArw9AGzsrLcfs/MzFRUVJTy8/PVtWtXlZSUaNGiRVq2bJm6d+8uScrIyFCLFi20detWPfDAA1q7dq327t2rdevWyW63q02bNpo+fbr+7//+T88//7yCgoI8PTYAAIAR1X7NV0lJiSQpMjJSkpSfn6+KigolJiZaa5o3b6477rhDubm5kqTc3FzFx8fLbrdba5KSkuR0OlVQUFDdIwMAAFQbj5/5+qbKykqNGzdOnTp10j333CNJcjgcCgoKUkREhNtau90uh8NhrflmeF3Zf2VfVcrKylRWVmb97nQ6PfVnAAAAeEy1nvlKTU3Vnj179MYbb1Tnw0i6fKF/eHi4dWvUqFG1PyYAAMCNqrb4Gjt2rNasWaMPPvhADRs2tLZHR0ervLxcxcXFbusLCwsVHR1trbn63Y9Xfr+y5moTJ05USUmJdTt27JgH/xoAAADP8Hh8uVwujR07VitXrtT69esVGxvrtr9du3YKDAxUTk6OtW3//v06evSoEhISJEkJCQnavXu3ioqKrDXZ2dmy2Wxq2bJllY8bHBwsm83mdgMAAPA1Hr/mKzU1VcuWLdPbb7+tsLAw6xqt8PBw1a5dW+Hh4Ro5cqTGjx+vyMhI2Ww2/e53v1NCQoIeeOABSVLPnj3VsmVLDR48WLNmzZLD4dCkSZOUmpqq4OBgT48MAABgjMfja+HChZKkn/3sZ27bMzIyNGzYMEnSn/70J/n7+6t///4qKytTUlKS/vrXv1pra9WqpTVr1mjMmDFKSEhQaGiohg4dqmnTpnl6XAAAAKM8Hl8ul+s714SEhGjBggVasGDBddc0btxY7733nidHAwAA8Dq+2xEAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAg4gsAAMAgn46vBQsWqEmTJgoJCVGHDh20bds2b48EAADwo/hsfP3zn//U+PHj9dxzz2nHjh1q3bq1kpKSVFRU5O3RAAAAfjCfja85c+Zo1KhRGj58uFq2bKn09HTVqVNHr776qrdHAwAA+MECvD1AVcrLy5Wfn6+JEyda2/z9/ZWYmKjc3Nwq71NWVqaysjLr95KSEkmS0+ms1lkry76u1uN7S3X/u3lTTX3OJJ63mxHP2c2J5+3mVJ3P25Vju1yu71zrk/F16tQpXbp0SXa73W273W7XJ598UuV90tLSNHXq1Gu2N2rUqFpmrOnC53p7AvwQPG83H56zmxPP283JxPN29uxZhYeHf+san4yvH2LixIkaP3689XtlZaVOnz6tevXqyc/Pz4uTeYbT6VSjRo107Ngx2Ww2b4+D74nn7ebDc3Zz4nm7+dS058zlcuns2bOKiYn5zrU+GV/169dXrVq1VFhY6La9sLBQ0dHRVd4nODhYwcHBbtsiIiKqa0SvsdlsNeI/pLcanrebD8/ZzYnn7eZTk56z7zrjdYVPXnAfFBSkdu3aKScnx9pWWVmpnJwcJSQkeHEyAACAH8cnz3xJ0vjx4zV06FC1b99e999/v+bOnavS0lINHz7c26MBAAD8YD4bXwMGDNCXX36pKVOmyOFwqE2bNsrKyrrmIvxbRXBwsJ577rlrXlqFb+N5u/nwnN2ceN5uPrfyc+bn+j7viQQAAIBH+OQ1XwAAADUV8QUAAGAQ8QUAAGAQ8eXjzp8/rylTpuiuu+5SSEiIYmJiNGLECH3xxRfeHg1VyM/P18yZM9WvXz81bNhQfn5+NeJDfmuyr7/+WqtWrdLIkSN19913KyQkRKGhoWrdurWmTZumc+fOeXtEXMecOXPUr18/xcXFKTw8XMHBwWrcuLGGDBmi3bt3e3s8fA9fffWVoqKi5Ofnp2bNmnl7HGO44N6HXbhwQQ8++KC2bt2qBg0aqEuXLvr888+1bds23X777dq6davuvPNOb4+Jb+jbt6/efvvta7bzXzPf9Y9//EOjRo2SJLVo0UL33HOPnE6ntmzZorNnz6p58+basGGDoqKivDwprla/fn2VlpaqVatW+slPfiJJKigo0IEDBxQYGKh//etf6t27t5enxLcZNmyYlixZIpfLpaZNm+rTTz/19khmuOCz/vCHP7gkuRISElxnz561tr/88ssuSa5u3bp5bzhUaebMma7Jkye73nnnHdfJkyddwcHBLv5r5tsyMzNdo0ePdu3du9dt+4kTJ1xt27Z1SXINGjTIS9Ph22zatMl1/vz5a7YvWLDAJcllt9tdFRUVXpgM38e6detcklyjR492SXI1bdrU2yMZw5kvH1VeXq6oqCiVlJRox44datu2rdv+1q1ba9euXfrwww/Vrl07L02J7xISEqKysjLOfN2kcnNz1bFjRwUHB8vpdCooKMjbI+F7atasmQ4dOqSPP/5YrVq18vY4uMr58+cVHx+v4OBgrVq1SnfdddctdeaLa7581ObNm1VSUqKmTZteE16S9Oijj0qSVq9ebXo04JbRunVrSVJZWZm++uorL0+DGxEYGChJBLOPmjp1qj777DOlp6dbz9WthPjyUR9//LEk6d57761y/5Xtu3btMjYTcKv57LPPJF3+H/LIyEgvT4Pv67XXXtP+/fsVFxenuLg4b4+Dq+zatUsvv/yyhg8fri5dunh7HK/w2a8XutUdPXpUktSwYcMq91/ZfuTIEWMzAbeaP//5z5KkXr163ZJfgXKzeOmll1RQUKDS0lLt27dPBQUFiomJ0fLly1WrVi1vj4dvqKys1GOPPaaIiAjNmjXL2+N4DfHlo668vb1OnTpV7g8NDZUknT171thMwK3kvffe06JFixQYGKjp06d7exx8i/fff185OTnW740bN9aSJUu4HtYHzZ8/X9u3b1dGRobq1avn7XG8hpcdAeAqn3zyiX7zm9/I5XLppZdesq79gm9at26dXC6Xzpw5o40bNyouLk7dunXTjBkzvD0avuHo0aOaNGmSunXrpmHDhnl7HK8ivnxU3bp1JV3+AMiqlJaWSpLCwsKMzQTcCr744gv16tVLZ86c0fjx4/XEE094eyR8TxEREerSpYvee+89tWvXTpMnT9b27du9PRb+v9TUVJWXlys9Pd3bo3gdLzv6qDvuuEOSdPz48Sr3X9neuHFjYzMBNd3p06fVs2dPHTlyRMOHD9fs2bO9PRJ+gMDAQA0YMED5+flavXq17rvvPm+PBElr1qxRRESE/ud//sdt+4ULFyRd/j8+P/vZzyRJb7zxhqKjo02PaAzx5aOuvMyxY8eOKvdf2c7n1wCece7cOT300EPau3ev+vXrp1deeYWvhrqJ1a9fX5L05ZdfenkSfFNxcbE2bNhQ5b4LFy5Y+64EWU3Fy44+qlOnTgoPD9ehQ4e0c+fOa/a/9dZbkqRHHnnE8GRAzVNWVqY+ffpo27ZtSkpK4l1yNcCV/xFv2rSplyfBFS6Xq8rb4cOHJV1+rq5sa9KkiXeHrWbEl48KCgrS2LFjJV1+nfzKNV7S5S+T3bVrl7p168a7eYAf6dKlSxo0aJDWr1+vLl266F//+hcfzHkT2Lx5s7KyslRZWem2vaKiQvPnz9drr72m2rVra8CAAV6aELg+Xnb0YZMmTdK6deu0ZcsWxcXFqUuXLjpy5Ijy8vJ0++2369VXX/X2iLjKu+++6/axBOXl5ZKkBx54wNo2efJkJScnG58NVfvLX/6ilStXSrr8UtXjjz9e5brZs2dbL2XB+w4ePKjhw4erfv36ateunerVq6dTp05p9+7dOnnypEJCQpSZmalGjRp5e1TgGsSXDwsJCdEHH3ygtLQ0LVu2TKtWrVJkZKSGDRum6dOnX/cDWOE9X375pfLy8q7Z/s1tXIPiW86cOWP9fCXCqvL8888TXz6kW7duevbZZ7Vhwwbt2rVLp06dUlBQkJo0aaJHH31Uv//979WsWTNvjwlUiS/WBgAAMIhrvgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAwivgAAAAz6f/wSc1L4TGnqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1.0    1011\n",
      "2.0     973\n",
      "3.0     970\n",
      "0.0     892\n",
      "4.0     706\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# 데이터 분포 꽤나 balance !! \n",
    "feature = train['class']\n",
    "\n",
    "plt.figure(figsize=(7,5)) \n",
    "plt.title('class', fontsize=20)\n",
    "temp = feature.value_counts() # feature 변수의 변수별 개수 계산\n",
    "plt.bar(temp.keys(), temp.values, width=0.5)\n",
    "plt.xticks(temp.keys(), fontsize=15) \n",
    "plt.show()\n",
    "print(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Conversation Length:  885\n",
      "Min Conversation Length:  41\n",
      "Mean Conversation Lenght:  257.6258787346221\n"
     ]
    }
   ],
   "source": [
    "print('Max Conversation Length: ', np.max(train['conversation'].str.len()))  #전제 최대는 90자, 최소는 19자\n",
    "print('Min Conversation Length: ', np.min(train['conversation'].str.len()))\n",
    "print('Mean Conversation Lenght: ',np.mean(train['conversation'].str.len()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEED 고정, GPU설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed:int = 1004):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "klue/roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ZAMTOL\\.cache\\huggingface\\hub\\models--klue--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"klue/roberta-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT \n",
    "train, val = train_test_split(train, test_size=0.2, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>야 너 이 새끼 뭐 사러 가냐  네  왜요  너 오늘 돈 많아 보인다 좀 살면 돈 ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>도저히 상황이 안돼서 말씀하신 기간까지 마련하지 못한 점 죄송하게 생각합네다  그래...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>빨리빨리 일 처리 안 해   죄송합니다  김대리 이번에는 승진해야지 죄송합니다 빨리...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>요새 애들은 소갈머리가 없어 맞아요 부장님 죄송합니다 나때는 고개도 못들었어 난 눈...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>이번 주말에 여행 갈까  어디로  해변으로 가고 싶어  좋아  그럼 계획 세워보자 ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           conversation  class\n",
       "714   야 너 이 새끼 뭐 사러 가냐  네  왜요  너 오늘 돈 많아 보인다 좀 살면 돈 ...    2.0\n",
       "388   도저히 상황이 안돼서 말씀하신 기간까지 마련하지 못한 점 죄송하게 생각합네다  그래...    0.0\n",
       "3549  빨리빨리 일 처리 안 해   죄송합니다  김대리 이번에는 승진해야지 죄송합니다 빨리...    3.0\n",
       "1874  요새 애들은 소갈머리가 없어 맞아요 부장님 죄송합니다 나때는 고개도 못들었어 난 눈...    3.0\n",
       "1667  이번 주말에 여행 갈까  어디로  해변으로 가고 싶어  좋아  그럼 계획 세워보자 ...    4.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아가씨 담배 한 갑 주소 네 4 500원입니다  어 네 지갑 어디 갔지  에이 버스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>우리 팀에서 다른 팀으로 갈 사람 없나  그럼  영지씨가 가는 건 어때  네  제가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요  제대로 좀 하지 네 똑바로 좀 하지 행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이거 들어봐 와 이 노래 진짜 좋다 그치 요즘 이것만 들어 진짜 너무 좋다 내가 요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무튼 앞으로 네가 내 와이파이야  응 와이파이 온  켰어  반말  주인님이라고도 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  아가씨 담배 한 갑 주소 네 4 500원입니다  어 네 지갑 어디 갔지  에이 버스...\n",
       "1  우리 팀에서 다른 팀으로 갈 사람 없나  그럼  영지씨가 가는 건 어때  네  제가...\n",
       "2  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요  제대로 좀 하지 네 똑바로 좀 하지 행...\n",
       "3  이거 들어봐 와 이 노래 진짜 좋다 그치 요즘 이것만 들어 진짜 너무 좋다 내가 요...\n",
       "4  아무튼 앞으로 네가 내 와이파이야  응 와이파이 온  켰어  반말  주인님이라고도 ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('klue/roberta-large')\n",
    "config.num_labels = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('klue/roberta-large', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128  # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(sent_list, max_seq_len, tokenizer):\n",
    "\n",
    "    input_ids, attention_masks, token_type_ids = [], [], []\n",
    "\n",
    "    for sent in tqdm(sent_list, total=len(sent_list)):\n",
    "        encoding_result = tokenizer.encode_plus(\n",
    "            sent,\n",
    "            max_length=max_seq_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoding_result['input_ids'])\n",
    "        attention_masks.append(encoding_result['attention_mask'])\n",
    "        token_type_ids.append(encoding_result['token_type_ids'])\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3641 [00:00<?, ?it/s]c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 3641/3641 [00:00<00:00, 4287.83it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = convert_examples_to_features(train['conversation'],  max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    0   732  2116  4022   733   568  1376  2203  2275   732   780  6233\n",
      "   752  2116  5390  2470   568  1170  2180  2778  1376  1170  6074  3866\n",
      "  8835  3637  2728  2073  2227  2203  2275  1110  2069  2113  2116  2899\n",
      "  2062  6148  2097  3690  2259  1378  5014  2318   743  1504  7171 24402\n",
      "  1169   732  2116  3842  8705  3949 12421  2170  3839  2015  2529  3949\n",
      " 23548   770  2052   717  2079  6045  2470  1389  2057  2138  3914  4577\n",
      "  2529  6791  2154  7624  2097  2223  2181  4458  6892  2170  5331  4962\n",
      "  2371  2088   752  4369  1875  2151  2042  2066  3679  2201  2203  2965\n",
      "  3869  2097     2     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : [CLS] 내가 사고 낸 거 아네야 내 눈으로 네가 운전한 거 봤거든 아 봤구나 그런데 일부러 그런것은아네야 믿을수가없다 미안해 다시는 안 그럴게 너 이 새끼 두고 봐 내가 어떻게하나 친구사이에 이러기냐 친구라는 놈이 나의 소중한 애마를 그렇게 만드냐 한번만 용서해주라 일단 경찰서에 증거 제출했고 네 가정 풍비박산 만들테네깐 기대해 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이: 128\n",
    "input_id = X_train[0][0]\n",
    "attention_mask = X_train[1][0]\n",
    "token_type_id = X_train[2][0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('어텐션 마스크 :',attention_mask)\n",
    "print('세그먼트 인코딩 :',token_type_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 911/911 [00:00<00:00, 4054.16it/s]\n"
     ]
    }
   ],
   "source": [
    "X_valid = convert_examples_to_features(val['conversation'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 3933.44it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = convert_examples_to_features(test['text'],max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train['class'].tolist()\n",
    "val_label = val['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4}\n",
      "{0: 0.0, 1: 1.0, 2: 2.0, 3: 3.0, 4: 4.0}\n"
     ]
    }
   ],
   "source": [
    "idx_encode = preprocessing.LabelEncoder()\n",
    "idx_encode.fit(train_label)\n",
    "\n",
    "y_train = idx_encode.transform(train_label) # 주어진 고유한 정수로 변환\n",
    "y_val = idx_encode.transform(val_label) # 고유한 정수로 변환\n",
    "\n",
    "label_idx = dict(zip(list(idx_encode.classes_), idx_encode.transform(list(idx_encode.classes_))))\n",
    "idx_label = {value: key for key, value in label_idx.items()}\n",
    "print(label_idx)\n",
    "print(idx_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"'klue/roberta-large'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "class Klue_RobertaClassifier(Model):\n",
    "    def __init__(self, model_name):\n",
    "        super(Klue_RobertaClassifier, self).__init__()\n",
    "        self.bert = TFAutoModel.from_pretrained(\"klue/roberta-large\", num_labels=3, from_pt=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "        self.classifier = Dense(3, kernel_initializer=TruncatedNormal(0.02),activation='softmax') #가중치 초기화, 활성화함수\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        input_ids, attention_mask, token_type_ids=inputs\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        prediction = self.classifier(pooled_output)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'roberta.embeddings.position_ids', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Klue_RobertaClassifier(\"klue/roberta-large\")  #dropout=0.5까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "optimizer = AdamWeightDecay(1e-5, weight_decay_rate=1e-4)  #과적합 방지\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'klue__roberta_classifier/tf_roberta_model/roberta/encoder/layer_._5/output/dropout_17/dropout/random_uniform/RandomUniform' defined at (most recent call last):\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ZAMTOL\\AppData\\Local\\Temp\\ipykernel_3172\\1473305745.py\", line 8, in <module>\n      model.fit(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ZAMTOL\\AppData\\Local\\Temp\\ipykernel_3172\\2813980160.py\", line 15, in call\n      outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1009, in run_call_with_unpacked_inputs\n      symbolic_weight_name = \"/\".join(symbolic_weight.name.split(\"/\")[1:])\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1036, in call\n      outputs = self.roberta(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1009, in run_call_with_unpacked_inputs\n      symbolic_weight_name = \"/\".join(symbolic_weight.name.split(\"/\")[1:])\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 828, in call\n      encoder_outputs = self.encoder(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 611, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 617, in call\n      layer_outputs = layer_module(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 556, in call\n      layer_output = self.bert_output(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 464, in call\n      hidden_states = self.dropout(inputs=hidden_states, training=training)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 111, in call\n      output = control_flow_util.smart_cond(training, dropped_inputs,\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 108, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\backend.py\", line 1940, in dropout\n      return tf.nn.dropout(inputs, rate=rate, noise_shape=noise_shape,\nNode: 'klue__roberta_classifier/tf_roberta_model/roberta/encoder/layer_._5/output/dropout_17/dropout/random_uniform/RandomUniform'\nOOM when allocating tensor with shape[8,128,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node klue__roberta_classifier/tf_roberta_model/roberta/encoder/layer_._5/output/dropout_17/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_46794]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      3\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m      4\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      5\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m      6\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'klue__roberta_classifier/tf_roberta_model/roberta/encoder/layer_._5/output/dropout_17/dropout/random_uniform/RandomUniform' defined at (most recent call last):\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ZAMTOL\\AppData\\Local\\Temp\\ipykernel_3172\\1473305745.py\", line 8, in <module>\n      model.fit(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ZAMTOL\\AppData\\Local\\Temp\\ipykernel_3172\\2813980160.py\", line 15, in call\n      outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1009, in run_call_with_unpacked_inputs\n      symbolic_weight_name = \"/\".join(symbolic_weight.name.split(\"/\")[1:])\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1036, in call\n      outputs = self.roberta(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1009, in run_call_with_unpacked_inputs\n      symbolic_weight_name = \"/\".join(symbolic_weight.name.split(\"/\")[1:])\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 828, in call\n      encoder_outputs = self.encoder(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 611, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 617, in call\n      layer_outputs = layer_module(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 556, in call\n      layer_output = self.bert_output(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 464, in call\n      hidden_states = self.dropout(inputs=hidden_states, training=training)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 111, in call\n      output = control_flow_util.smart_cond(training, dropped_inputs,\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 108, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"c:\\Users\\ZAMTOL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\backend.py\", line 1940, in dropout\n      return tf.nn.dropout(inputs, rate=rate, noise_shape=noise_shape,\nNode: 'klue__roberta_classifier/tf_roberta_model/roberta/encoder/layer_._5/output/dropout_17/dropout/random_uniform/RandomUniform'\nOOM when allocating tensor with shape[8,128,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node klue__roberta_classifier/tf_roberta_model/roberta/encoder/layer_._5/output/dropout_17/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_46794]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001,\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=3, batch_size=8, validation_data=(X_valid, y_val),\n",
    "    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
